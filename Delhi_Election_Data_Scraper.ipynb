{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This project scrapes Delhi 2020 election data from the ECI website. \n",
    "\n",
    "## For each of the 70 constituencies, the following variables have been scraped: name of constituency, number of contesting candidates, total votes polled, winning party in 2020, margin of victory in 2020, winning party in 2015, margin of victory in 2015\n",
    "\n",
    "### The code can be executed through the main() at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-40-d1c23a20aae7>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-d1c23a20aae7>\"\u001b[1;36m, line \u001b[1;32m24\u001b[0m\n\u001b[1;33m    vote_row = soup.find(attrs={\"style\":\"color:#000000;background-color:White;\u001b[0m\n\u001b[1;37m                                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#this function scrapes three variables - name of constituency, number of candidates, total votes polled - for each constituency\n",
    "def scrape_name_candidates_votes(page_number):\n",
    "    name_of_const = []\n",
    "    #the tentative variables for name of constituency are used to get to the final name (name_of_const) \n",
    "    tentative1_name_of_const = []\n",
    "    tentative2_name_of_const = []\n",
    "    \n",
    "    number_of_candidates = []\n",
    "    \n",
    "    total_votes = []\n",
    "    #td_list is used to scrape td tags, in order to append total_votes \n",
    "    td_list = []\n",
    "\n",
    "    for i in (page_number):\n",
    "                #the variable page goes to each URL on the website\n",
    "                page = requests.get('http://results.eci.gov.in/DELHITRENDS2020/ConstituencywiseU05' \n",
    "                                    + i +'.htm')\n",
    "                soup = BeautifulSoup(page.content, 'html.parser')\n",
    "                #the next three lines of code scrape number of candidates in each constituency\n",
    "                full_table = soup.find_all(attrs={\"style\":\"font-size:12px;\"})\n",
    "                if (len(full_table) is not 0):\n",
    "                    number_of_candidates.append(len(full_table))\n",
    "                # the next 4 lines scrape total votes polled in each constituency\n",
    "                vote_row = soup.find(attrs={\"style\":\"color:#000000;background-color:White;\n",
    "                                             border-color:#673033;border-width:1px;border-style:\n",
    "                                             Solid;font-family:Calibri;font-size:Small;background-color: pink\"})\n",
    "                if (vote_row is not None):\n",
    "                        td_list = vote_row.find_all(\"td\")\n",
    "                        total_votes.append(td_list[5].get_text())\n",
    "                \n",
    "                name_row = soup.find(attrs={\"style\": \"height: 20px; background-color:#FFC0CD; \n",
    "                                            color:Black; font-weight: bold\"})\n",
    "                if (name_row is not None):\n",
    "                      # the name is split on \"-\" because it's initially scraped as <Name of State-Name of Constituency>\n",
    "                        tentative1_name_of_const.append(name_row.find(\"td\").get_text())\n",
    "                        tentative2_name_of_const.append(tentative1_name_of_const[-1].strip().split(\"-\")) \n",
    "    #the tuple is used to extract Name of Constituency after splitting on \"-\"\n",
    "    temporary_tuple = tuple(tentative2_name_of_const)\n",
    "    name_of_const = [t[1] for t in temporary_tuple]\n",
    "    combined_name_candidates_votes = list(zip(name_of_const, number_of_candidates, total_votes))\n",
    "    \n",
    "    return (combined_name_candidates_votes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function scrapes three variables - name of constituency, winning party in 2020, margin of victory in 2020, winning party in 2015, margin of victory in 2015 - for each constituency\n",
    "def scrape_name_margin_party(page_number):\n",
    "    name_of_const = []\n",
    "    \n",
    "    margin_2020 = []\n",
    "    winning_party_2020 = []\n",
    "    \n",
    "    margin_2015 = []\n",
    "    winning_party_2015 = []\n",
    "    \n",
    "    for i in (page_number):\n",
    "                page = requests.get('http://results.eci.gov.in/DELHITRENDS2020/statewiseU05' + \n",
    "                                    i + '.htm')\n",
    "                soup = BeautifulSoup(page.content, 'html.parser')\n",
    "                full_table = soup.find_all(attrs={\"style\":\"font-size:12px;\"})\n",
    "                for td in full_table:\n",
    "                    name_of_const.append(td.find('td').get_text())\n",
    "                   \n",
    "                    margin_2020.append(td.find(attrs={\"align\":\"right\"}).get_text())\n",
    "                    winning_party_2020.append(td.find(\"tbody\").find(\"td\").get_text())\n",
    "                    \n",
    "                    data_2015 = td.find_all(attrs={\"style\": \"background-color: lightgray;\"})\n",
    "                    winning_party_2015.append(data_2015[1].get_text())\n",
    "                    margin_2015.append(data_2015[2].get_text())\n",
    "                    \n",
    "    combined_name_margin_party = list(zip(name_of_const, winning_party_2020, margin_2020, winning_party_2015, margin_2015))\n",
    "    #print(combined_name_margin_party)\n",
    "    #print(type(combined_name_margin_party))\n",
    "    return(combined_name_margin_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function merges the above two dataframes\n",
    "def data_merge(combined_name_candidates_votes, combined_name_margin_party):\n",
    "    const_cand_votes_df = pd.DataFrame(np.array(combined_name_candidates_votes)\n",
    "                                       .reshape(len(combined_name_candidates_votes),3), \n",
    "                                       columns = ['Constituency','Number_of_candidates', 'Total_votes_2020'])\n",
    "    const_party_margin_df = pd.DataFrame(np.array(combined_name_margin_party)\n",
    "                                         .reshape(len(combined_name_margin_party),5), \n",
    "                                         columns = ['Constituency' , 'Winning_party_2020', 'Margin_2020', 'Winning_party_2015', 'Margin_2015'])\n",
    "    \n",
    "    data_Delhi_merged = pd.merge(const_cand_votes_df, const_party_margin_df, on='Constituency')\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(data_Delhi_merged.head())\n",
    "    \n",
    "    return(data_Delhi_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function exports all the data to the user's harddrive\n",
    "def write_merged_csv_file(data_Delhi_merged):\n",
    "    data_Delhi_merged.to_csv('Delhi_election_data.csv', sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function generates the different URLs on the ECI website from where the data is scraped\n",
    "def generate_page_numbers():\n",
    "    page_number = []\n",
    "    for i in range(1, 6):\n",
    "        str_i = str(i)\n",
    "        page_number.append(str_i)\n",
    "    \n",
    "    return page_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    page_number = generate_page_numbers()\n",
    "    combined_name_candidates_votes = scrape_name_candidates_votes(page_number)\n",
    "    combined_name_margin_party = scrape_name_margin_party(page_number)\n",
    "    data_Delhi_merged = data_merge(combined_name_candidates_votes, combined_name_margin_party)\n",
    "    #write_merged_csv_file(data_Delhi_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Constituency Number_of_candidates Total_votes_2020 Winning_party_2020  \\\n",
      "0        NARELA                   12           165694    Aam Aadmi Party   \n",
      "1        BURARI                   23           222256    Aam Aadmi Party   \n",
      "2  ADARSH NAGAR                    8           103752    Aam Aadmi Party   \n",
      "3         BADLI                   14           139638    Aam Aadmi Party   \n",
      "\n",
      "  Margin_2020 Winning_party_2015 Margin_2015  \n",
      "0       17429    Aam Aadmi Party       40292  \n",
      "1       88158    Aam Aadmi Party       67950  \n",
      "2        1589    Aam Aadmi Party       20741  \n",
      "3       29123    Aam Aadmi Party       35376  \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
